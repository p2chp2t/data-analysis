{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5-1 Classification\n",
    "20220041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 22 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SEASON_ID   15000 non-null  object \n",
      " 1   TEAM_ID     15000 non-null  int64  \n",
      " 2   PLAYER_AGE  15000 non-null  float64\n",
      " 3   FGM         15000 non-null  int64  \n",
      " 4   FGA         15000 non-null  int64  \n",
      " 5   FG_PCT      14994 non-null  float64\n",
      " 6   FG3M        12057 non-null  float64\n",
      " 7   FG3A        12057 non-null  float64\n",
      " 8   FG3_PCT     11955 non-null  float64\n",
      " 9   FTM         15000 non-null  int64  \n",
      " 10  FTA         15000 non-null  int64  \n",
      " 11  FT_PCT      14952 non-null  float64\n",
      " 12  OREB        12931 non-null  float64\n",
      " 13  DREB        12931 non-null  float64\n",
      " 14  REB         14662 non-null  float64\n",
      " 15  AST         15000 non-null  int64  \n",
      " 16  STL         12931 non-null  float64\n",
      " 17  BLK         12931 non-null  float64\n",
      " 18  TOV         12399 non-null  float64\n",
      " 19  PF          15000 non-null  int64  \n",
      " 20  PTS         15000 non-null  int64  \n",
      " 21  position    14897 non-null  object \n",
      "dtypes: float64(12), int64(8), object(2)\n",
      "memory usage: 2.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data loading & selection\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "train_feature = train_data.drop(columns=['position'])\n",
    "train_label = train_data['position']\n",
    "\n",
    "extra_cols = set(train_feature.columns) - set(test_data.columns)\n",
    "train_data = train_data.drop(columns=extra_cols)\n",
    "\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11862 entries, 0 to 14999\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SEASON_ID   11862 non-null  object \n",
      " 1   TEAM_ID     11862 non-null  int64  \n",
      " 2   PLAYER_AGE  11862 non-null  float64\n",
      " 3   FGM         11862 non-null  int64  \n",
      " 4   FGA         11862 non-null  int64  \n",
      " 5   FG_PCT      11862 non-null  float64\n",
      " 6   FG3M        11862 non-null  float64\n",
      " 7   FG3A        11862 non-null  float64\n",
      " 8   FG3_PCT     11862 non-null  float64\n",
      " 9   FTM         11862 non-null  int64  \n",
      " 10  FTA         11862 non-null  int64  \n",
      " 11  FT_PCT      11862 non-null  float64\n",
      " 12  OREB        11862 non-null  float64\n",
      " 13  DREB        11862 non-null  float64\n",
      " 14  REB         11862 non-null  float64\n",
      " 15  AST         11862 non-null  int64  \n",
      " 16  STL         11862 non-null  float64\n",
      " 17  BLK         11862 non-null  float64\n",
      " 18  TOV         11862 non-null  float64\n",
      " 19  PF          11862 non-null  int64  \n",
      " 20  PTS         11862 non-null  int64  \n",
      "dtypes: float64(12), int64(8), object(1)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Ignore tuples with missing values\n",
    "train_data_clean = train_data.dropna()\n",
    "train_feature_clean = train_data_clean.drop(columns=['position'])\n",
    "train_label_clean = train_data_clean['position']\n",
    "\n",
    "print(train_feature_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11862 entries, 0 to 14999\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SEASON_ID   11862 non-null  int64  \n",
      " 1   TEAM_ID     11862 non-null  int64  \n",
      " 2   PLAYER_AGE  11862 non-null  float64\n",
      " 3   FGM         11862 non-null  int64  \n",
      " 4   FGA         11862 non-null  int64  \n",
      " 5   FG_PCT      11862 non-null  float64\n",
      " 6   FG3M        11862 non-null  float64\n",
      " 7   FG3A        11862 non-null  float64\n",
      " 8   FG3_PCT     11862 non-null  float64\n",
      " 9   FTM         11862 non-null  int64  \n",
      " 10  FTA         11862 non-null  int64  \n",
      " 11  FT_PCT      11862 non-null  float64\n",
      " 12  OREB        11862 non-null  float64\n",
      " 13  DREB        11862 non-null  float64\n",
      " 14  REB         11862 non-null  float64\n",
      " 15  AST         11862 non-null  int64  \n",
      " 16  STL         11862 non-null  float64\n",
      " 17  BLK         11862 non-null  float64\n",
      " 18  TOV         11862 non-null  float64\n",
      " 19  PF          11862 non-null  int64  \n",
      " 20  PTS         11862 non-null  int64  \n",
      "dtypes: float64(12), int64(9)\n",
      "memory usage: 2.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data transformation\n",
    "train_feature_clean['SEASON_ID'] = train_feature_clean['SEASON_ID'].str[:4].astype(int)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_label_encode = encoder.fit_transform(train_label_clean)\n",
    "\n",
    "print(train_feature_clean.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features with low importance: ['TEAM_ID', 'FGM', 'FG3M', 'FG3_PCT', 'FTM', 'FTA', 'PTS']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11862 entries, 0 to 14999\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SEASON_ID   11862 non-null  int64  \n",
      " 1   PLAYER_AGE  11862 non-null  float64\n",
      " 2   FGA         11862 non-null  int64  \n",
      " 3   FG_PCT      11862 non-null  float64\n",
      " 4   FG3A        11862 non-null  float64\n",
      " 5   FT_PCT      11862 non-null  float64\n",
      " 6   OREB        11862 non-null  float64\n",
      " 7   DREB        11862 non-null  float64\n",
      " 8   REB         11862 non-null  float64\n",
      " 9   AST         11862 non-null  int64  \n",
      " 10  STL         11862 non-null  float64\n",
      " 11  BLK         11862 non-null  float64\n",
      " 12  TOV         11862 non-null  float64\n",
      " 13  PF          11862 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 1.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compute feature importance using Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=10000)\n",
    "dt.fit(train_feature_clean, train_label_encode)\n",
    "feature_importances = dt.feature_importances_\n",
    "\n",
    "low_importance_features = [col for col, importance in zip(train_feature_clean.columns, feature_importances) if importance < 0.03]\n",
    "\n",
    "print(\"features with low importance:\", low_importance_features)\n",
    "\n",
    "# Reduce feature with low importance\n",
    "train_feature_reduced = train_feature_clean.drop(columns=low_importance_features)\n",
    "\n",
    "print(train_feature_reduced.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_feature_scaled = scaler.fit_transform(train_feature_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "feature_train, feature_val, label_train, label_val = train_test_split(\n",
    "    train_feature_scaled,\n",
    "    train_label_encode,\n",
    "    test_size=0.2,\n",
    "    random_state=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. xgb f1 score: 0.6388963922500461\n"
     ]
    }
   ],
   "source": [
    "# 1. XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softmax',  # multiclass classification\n",
    "    num_class=len(set(label_train)),  # number of classes\n",
    "    random_state=50\n",
    ")\n",
    "\n",
    "xgb.fit(feature_train, label_train)\n",
    "\n",
    "label_pred_xgb = xgb.predict(feature_val)\n",
    "\n",
    "f1_xgb = f1_score(label_val, label_pred_xgb, average='weighted')\n",
    "print(\"1. xgb f1 score:\", f1_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "best params for xgb: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}\n",
      "1+. best xgb f1 score: 0.6484065377377887\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for xgb\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    XGBClassifier(objective='multi:softmax', num_class=len(set(label_train)), random_state=50),\n",
    "    param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(feature_train, label_train)\n",
    "print(\"best params for xgb:\", grid_search.best_params_)\n",
    "\n",
    "# Prediction with best xgb\n",
    "best_xgb = grid_search.best_estimator_\n",
    "label_pred_best_xgb = best_xgb.predict(feature_val)\n",
    "f1_best_xgb = f1_score(label_val, label_pred_best_xgb, average='weighted')\n",
    "\n",
    "print(\"1+. best xgb f1 score:\", f1_best_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. rf f1 score: 0.6254862275851781\n"
     ]
    }
   ],
   "source": [
    "# 2. Random forest\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=50)\n",
    "rf.fit(feature_train, label_train)\n",
    "\n",
    "label_pred_rf = rf.predict(feature_val)\n",
    "f1_rf = f1_score(label_val, label_pred_rf, average='weighted')\n",
    "print(\"2. rf f1 score:\", f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for rf: {'max_depth': 30, 'n_estimators': 200}\n",
      "2+. best rf f1 score: 0.6273757503726072\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for rf\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=10000),\n",
    "    param_grid_rf,\n",
    "    scoring='f1_weighted',  \n",
    "    cv=3,  \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(feature_train, label_train)\n",
    "\n",
    "print(\"best params for rf:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Prediction with best rf\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "label_pred_best_rf = best_rf.predict(feature_val)\n",
    "\n",
    "f1_best_rf = f1_score(label_val, label_pred_best_rf, average='weighted')\n",
    "print(\"2+. best rf f1 score:\", f1_best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'xgb.csv'\n"
     ]
    }
   ],
   "source": [
    "# Prediction on the test data\n",
    "test_data_clean = test_data.drop(columns=['ID'])\n",
    "test_data_clean['SEASON_ID'] = test_data_clean['SEASON_ID'].astype(str).str[:4].astype(int)\n",
    "test_data_clean_reduced = test_data_clean.drop(columns=low_importance_features)\n",
    "test_features_scaled = scaler.transform(test_data_clean_reduced)  # Scale test data\n",
    "\n",
    "test_pred = best_xgb.predict(test_features_scaled)\n",
    "\n",
    "test_pred_labels = encoder.inverse_transform(test_pred)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    'position': test_pred_labels\n",
    "})\n",
    "\n",
    "result.to_csv('xgb6.csv', index=False)\n",
    "print(\"Predictions saved to 'xgb.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
